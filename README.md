# CS188_NLP_Models
N-gram language model written as part of HW4 for class CS188 - "Introduction to Artificial Intelligence" at UC Berkeley during the Spring 2020 semester.

After some theoretical questions about using different ML models for NLP (e.g. Naive Bayes, N-gram), part of the homework was to implement an N-gram language model, train it with some corpora of text and then use it to generate new text.
The homework prompt can be accessed [here](https://github.com/philipp-kurz/CS170_NP_Comp_Approx/files/4707565/CS_188_Spring_2020_Written_Homework_4_v1.pdf).
